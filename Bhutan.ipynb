{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split as dsplit\n",
    "from rgf.sklearn import FastRGFClassifier, RGFClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import regularizers\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1221, 10)\n",
      "(1221,)\n"
     ]
    }
   ],
   "source": [
    "samples_file = pd.read_csv(r\"C:\\Users\\maher\\Desktop\\Data_Bhutan\\samples.csv\")\n",
    "X = samples_file.drop(['FID', 'CID', 'Type', 'Type_ID'], axis = 1)\n",
    "y = samples_file['Type_ID']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (610, 10)\n",
      "Training Labels Shape: (610,)\n",
      "Testing Features Shape: (611, 10)\n",
      "Testing Labels Shape: (611,)\n"
     ]
    }
   ],
   "source": [
    "xtr, xte, ytr, yte = dsplit(X.values, y.values, test_size = 0.5, random_state = 42,stratify = y)\n",
    "print('Training Features Shape:', xtr.shape)\n",
    "print('Training Labels Shape:', ytr.shape)\n",
    "print('Testing Features Shape:', xte.shape)\n",
    "print('Testing Labels Shape:', yte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rgf = RGFClassifier(calc_prob='sigmoid',learning_rate=0.01, loss='LS')\n",
    "rgf = rgf.fit(xtr, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187965, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_file = pd.read_csv(r\"C:\\Users\\maher\\Desktop\\Data_Bhutan\\whole.csv\")\n",
    "objectid = whole_file['OBJECTID']\n",
    "X_whole = whole_file.drop(['OBJECTID', 'pointid', 'grid_code'], axis = 1)\n",
    "X_whole.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x_tr, x_te, whole):\n",
    "    mean = np.mean(x_tr)\n",
    "    std_dev = np.std(x_tr)\n",
    "    x_norm_tr = (x_tr - mean) / std_dev \n",
    "    x_norm_te = (x_te - mean) / std_dev \n",
    "    whole_norm = (whole - mean) / std_dev \n",
    "    return x_norm_tr, x_norm_te, whole_norm\n",
    "\n",
    "_, _, X_whole= normalize(xtr, xte, X_whole)\n",
    "xtr, xte, _= normalize(xtr, xte, _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoencoder(object):\n",
    "    \n",
    "    def __init__(self, features, encoding_dim, opt, hidden_nodes, loss_fn, np_epochs, bsize, vsize):\n",
    "        self.features = features\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.opt = opt\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.loss_fn = loss_fn\n",
    "        self.np_epochs = np_epochs\n",
    "        self.bsize = bsize\n",
    "        self.vsize = vsize\n",
    "        self.autoencoder = None\n",
    "        self.encoder = None\n",
    "        self.create_autoencoder()\n",
    "        \n",
    "    def create_autoencoder(self):\n",
    "        input_features = Input(shape=(self.features.shape[1],))\n",
    "        \n",
    "        encoded1 = Dense(self.hidden_nodes, activation='relu', activity_regularizer=regularizers.l1(10e-5))(input_features)\n",
    "        encoded2 = Dense(self.encoding_dim, activation='relu', activity_regularizer=regularizers.l2(10e-5))(encoded1)\n",
    "        encoded3 = Dense(self.hidden_nodes, activation='relu', activity_regularizer=regularizers.l1(10e-5))(encoded2)\n",
    "\n",
    "        decoded = Dense(self.features.shape[1], activation='sigmoid')(encoded3)\n",
    "        autoencoder = Model(input_features, decoded)\n",
    "        autoencoder.compile(optimizer=self.opt, loss=self.loss_fn)\n",
    "        autoencoder.fit(self.features, self.features,epochs=self.np_epochs,batch_size=self.bsize,\n",
    "                        shuffle=True,validation_split=self.vsize)\n",
    "        encoder = Model(input = input_features, output = encoded2)\n",
    "        self.autoencoder = autoencoder\n",
    "        self.encoder = encoder\n",
    "        return\n",
    "    \n",
    "    def reconstruct_input(self, features):\n",
    "        reconstructed_features = self.autoencoder.predict(features)\n",
    "        return reconstructed_features\n",
    "    \n",
    "    def extract_compressed_features(self, features):\n",
    "        c_features = self.encoder.predict(x= features)\n",
    "        return c_features\n",
    "    \n",
    "    def measure_error(self, actual_features, reconstructed_features):\n",
    "        reconstruction_error = mean_squared_error(actual_features, reconstructed_features)\n",
    "        return reconstruction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "    \n",
    "def KLD(y_true, y_pred):\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1)\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
    "    return K.sum(y_true * K.log(y_true / y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGF(object):\n",
    "    \n",
    "    def __init__(self, xtr, xte, ytr, yte, lr):\n",
    "        self.xtr = xtr\n",
    "        self.xte = xte\n",
    "        self.ytr = ytr\n",
    "        self.yte = yte\n",
    "        self.lr = lr\n",
    "        self.tr_rgf = self.fit()\n",
    "        \n",
    "    def fit(self):\n",
    "        rgf = RGFClassifier(calc_prob='sigmoid',learning_rate=self.lr, loss='LS')\n",
    "        rgf = rgf.fit(self.xtr, self.ytr)\n",
    "        return rgf\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.tr_rgf.predict(x)\n",
    "    \n",
    "    def predict_proba(self,x):\n",
    "        return self.tr_rgf.predict_proba(x)\n",
    "    \n",
    "    def measure_accuracy(self, x, true_y):\n",
    "        preds = self.predict(x)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(true_y, preds, pos_label=1)\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        print('AUC = ', np.round(auc, 3))\n",
    "        return\n",
    "        \n",
    "    def rank_features(self, X):\n",
    "        feature_list = list(X.columns)\n",
    "        importances = list(self.tr_rgf.feature_importances_)\n",
    "        feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "        x_values = list(range(len(importances)))\n",
    "        plt.bar(x_values, importances, orientation = 'vertical')\n",
    "        plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "        plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');   \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class TreeModels(object):\n",
    "    def __init__(self, xtr, xte, ytr, yte, model):\n",
    "        self.xtr = xtr\n",
    "        self.xte = xte\n",
    "        self.ytr = ytr\n",
    "        self.yte = yte\n",
    "        self.model = model \n",
    "        self.trained_model = self.fit()\n",
    "        \n",
    "    def fit(self):\n",
    "        dt = DecisionTreeClassifier()\n",
    "        rf = RandomForestClassifier()\n",
    "        et = ExtraTreeClassifier()\n",
    "        dt = dt.fit(self.xtr, self.ytr)\n",
    "        rf = rf.fit(self.xtr, self.ytr)\n",
    "        et = et.fit(self.xtr, self.ytr)\n",
    "        if self.model == 'dt':\n",
    "            return dt\n",
    "        elif self.model == 'rf':\n",
    "            return rf\n",
    "        else:\n",
    "            return et\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.trained_model.predict(x)\n",
    "        \n",
    "    def predict_proba(self,x):\n",
    "        return self.trained_model.predict_proba(x)\n",
    "    \n",
    "    def measure_accuracy(self, x, true_y):\n",
    "        preds = self.predict(x)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(true_y, preds, pos_label=1)\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        print('AUC = ', np.round(auc, 3))\n",
    "        return\n",
    "        \n",
    "    def rank_features(self, X):\n",
    "        feature_list = list(X.columns)\n",
    "        importances = list(self.trained_model.feature_importances_)\n",
    "        feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "        x_values = list(range(len(importances)))\n",
    "        plt.bar(x_values, importances, orientation = 'vertical')\n",
    "        plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "        plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances : ' + self.model);   \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 603 samples, validate on 7 samples\n",
      "Epoch 1/800\n",
      "603/603 [==============================] - 1s 938us/step - loss: 0.6006 - val_loss: 0.5093\n",
      "Epoch 2/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: 0.3833 - val_loss: 0.2378\n",
      "Epoch 3/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: 0.0403 - val_loss: -0.1740\n",
      "Epoch 4/800\n",
      "603/603 [==============================] - 0s 52us/step - loss: -0.4620 - val_loss: -0.7403\n",
      "Epoch 5/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -1.1620 - val_loss: -1.4887\n",
      "Epoch 6/800\n",
      "603/603 [==============================] - 0s 49us/step - loss: -2.1113 - val_loss: -2.5604\n",
      "Epoch 7/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -3.4811 - val_loss: -4.1113\n",
      "Epoch 8/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -4.6440 - val_loss: -5.1147\n",
      "Epoch 9/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -4.9348 - val_loss: -5.2092\n",
      "Epoch 10/800\n",
      "603/603 [==============================] - 0s 47us/step - loss: -4.9908 - val_loss: -5.2100\n",
      "Epoch 11/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -5.0383 - val_loss: -5.2214\n",
      "Epoch 12/800\n",
      "603/603 [==============================] - 0s 53us/step - loss: -5.0787 - val_loss: -5.2246\n",
      "Epoch 13/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -5.1136 - val_loss: -5.2163\n",
      "Epoch 14/800\n",
      "603/603 [==============================] - 0s 46us/step - loss: -5.1455 - val_loss: -5.2222\n",
      "Epoch 15/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -5.1748 - val_loss: -5.2223\n",
      "Epoch 16/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -5.2030 - val_loss: -5.2236\n",
      "Epoch 17/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -5.2316 - val_loss: -5.2277\n",
      "Epoch 18/800\n",
      "603/603 [==============================] - 0s 49us/step - loss: -5.2601 - val_loss: -5.2277\n",
      "Epoch 19/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -5.2889 - val_loss: -5.2279\n",
      "Epoch 20/800\n",
      "603/603 [==============================] - 0s 46us/step - loss: -5.3189 - val_loss: -5.2296\n",
      "Epoch 21/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -5.3497 - val_loss: -5.2356\n",
      "Epoch 22/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -5.3859 - val_loss: -5.2429\n",
      "Epoch 23/800\n",
      "603/603 [==============================] - 0s 45us/step - loss: -5.4253 - val_loss: -5.2490\n",
      "Epoch 24/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -5.4717 - val_loss: -5.2563\n",
      "Epoch 25/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -5.5249 - val_loss: -5.2668\n",
      "Epoch 26/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -5.5842 - val_loss: -5.2960\n",
      "Epoch 27/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -5.6534 - val_loss: -5.3101\n",
      "Epoch 28/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -5.7318 - val_loss: -5.3301\n",
      "Epoch 29/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -5.8114 - val_loss: -5.3511\n",
      "Epoch 30/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -5.8901 - val_loss: -5.3745\n",
      "Epoch 31/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -5.9540 - val_loss: -5.3901\n",
      "Epoch 32/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -6.0093 - val_loss: -5.4044\n",
      "Epoch 33/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -6.0629 - val_loss: -5.4292\n",
      "Epoch 34/800\n",
      "603/603 [==============================] - 0s 46us/step - loss: -6.1186 - val_loss: -5.4405\n",
      "Epoch 35/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -6.1726 - val_loss: -5.4655\n",
      "Epoch 36/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -6.2260 - val_loss: -5.4732\n",
      "Epoch 37/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -6.2673 - val_loss: -5.4888\n",
      "Epoch 38/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -6.2994 - val_loss: -5.4847\n",
      "Epoch 39/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -6.3195 - val_loss: -5.4821\n",
      "Epoch 40/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -6.3361 - val_loss: -5.4885\n",
      "Epoch 41/800\n",
      "603/603 [==============================] - 0s 45us/step - loss: -6.3500 - val_loss: -5.4860\n",
      "Epoch 42/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -6.3620 - val_loss: -5.4779\n",
      "Epoch 43/800\n",
      "603/603 [==============================] - 0s 43us/step - loss: -6.3744 - val_loss: -5.4822\n",
      "Epoch 44/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -6.3860 - val_loss: -5.4788\n",
      "Epoch 45/800\n",
      "603/603 [==============================] - 0s 43us/step - loss: -6.3955 - val_loss: -5.4842\n",
      "Epoch 46/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -6.4041 - val_loss: -5.4800\n",
      "Epoch 47/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -6.4143 - val_loss: -5.4794\n",
      "Epoch 48/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -6.4217 - val_loss: -5.4845\n",
      "Epoch 49/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -6.4304 - val_loss: -5.4875\n",
      "Epoch 50/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -6.4375 - val_loss: -5.4928\n",
      "Epoch 51/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -6.4457 - val_loss: -5.4965\n",
      "Epoch 52/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -6.4541 - val_loss: -5.5016\n",
      "Epoch 53/800\n",
      "603/603 [==============================] - 0s 45us/step - loss: -6.4611 - val_loss: -5.5059\n",
      "Epoch 54/800\n",
      "603/603 [==============================] - 0s 43us/step - loss: -6.4678 - val_loss: -5.5111\n",
      "Epoch 55/800\n",
      "603/603 [==============================] - 0s 43us/step - loss: -6.4752 - val_loss: -5.5159\n",
      "Epoch 56/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -6.4836 - val_loss: -5.5239\n",
      "Epoch 57/800\n",
      "603/603 [==============================] - 0s 48us/step - loss: -6.4910 - val_loss: -5.5312\n",
      "Epoch 58/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -6.4989 - val_loss: -5.5418\n",
      "Epoch 59/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -6.5080 - val_loss: -5.5392\n",
      "Epoch 60/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -6.5158 - val_loss: -5.5488\n",
      "Epoch 61/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -6.5238 - val_loss: -5.5577\n",
      "Epoch 62/800\n",
      "603/603 [==============================] - 0s 51us/step - loss: -6.5329 - val_loss: -5.5717\n",
      "Epoch 63/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -6.5417 - val_loss: -5.5814\n",
      "Epoch 64/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -6.5517 - val_loss: -5.5913\n",
      "Epoch 65/800\n",
      "603/603 [==============================] - 0s 49us/step - loss: -6.5617 - val_loss: -5.5955\n",
      "Epoch 66/800\n",
      "603/603 [==============================] - 0s 46us/step - loss: -6.5722 - val_loss: -5.6036\n",
      "Epoch 67/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -6.5806 - val_loss: -5.6198\n",
      "Epoch 68/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -6.5912 - val_loss: -5.6300\n",
      "Epoch 69/800\n",
      "603/603 [==============================] - 0s 45us/step - loss: -6.6029 - val_loss: -5.6367\n",
      "Epoch 70/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -6.6137 - val_loss: -5.6512\n",
      "Epoch 71/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -6.6238 - val_loss: -5.6637\n",
      "Epoch 72/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -6.6378 - val_loss: -5.6760\n",
      "Epoch 73/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -6.6489 - val_loss: -5.6856\n",
      "Epoch 74/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -6.6647 - val_loss: -5.6980\n",
      "Epoch 75/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -6.6784 - val_loss: -5.7227\n",
      "Epoch 76/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -6.6935 - val_loss: -5.7309\n",
      "Epoch 77/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -6.7100 - val_loss: -5.7500\n",
      "Epoch 78/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 36us/step - loss: -6.7265 - val_loss: -5.7655\n",
      "Epoch 79/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -6.7447 - val_loss: -5.7799\n",
      "Epoch 80/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -6.7627 - val_loss: -5.8113\n",
      "Epoch 81/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -6.7814 - val_loss: -5.8248\n",
      "Epoch 82/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -6.8002 - val_loss: -5.8463\n",
      "Epoch 83/800\n",
      "603/603 [==============================] - 0s 45us/step - loss: -6.8181 - val_loss: -5.8619\n",
      "Epoch 84/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -6.8350 - val_loss: -5.8720\n",
      "Epoch 85/800\n",
      "603/603 [==============================] - 0s 43us/step - loss: -6.8494 - val_loss: -5.8985\n",
      "Epoch 86/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -6.8643 - val_loss: -5.9089\n",
      "Epoch 87/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -6.8779 - val_loss: -5.9252\n",
      "Epoch 88/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -6.8908 - val_loss: -5.9354\n",
      "Epoch 89/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -6.9037 - val_loss: -5.9468\n",
      "Epoch 90/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -6.9151 - val_loss: -5.9589\n",
      "Epoch 91/800\n",
      "603/603 [==============================] - 0s 45us/step - loss: -6.9284 - val_loss: -5.9721\n",
      "Epoch 92/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -6.9412 - val_loss: -5.9796\n",
      "Epoch 93/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -6.9529 - val_loss: -6.0016\n",
      "Epoch 94/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -6.9660 - val_loss: -6.0140\n",
      "Epoch 95/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -6.9770 - val_loss: -6.0178\n",
      "Epoch 96/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -6.9897 - val_loss: -6.0264\n",
      "Epoch 97/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.0002 - val_loss: -6.0474\n",
      "Epoch 98/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.0109 - val_loss: -6.0549\n",
      "Epoch 99/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.0209 - val_loss: -6.0594\n",
      "Epoch 100/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.0303 - val_loss: -6.0672\n",
      "Epoch 101/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.0400 - val_loss: -6.0695\n",
      "Epoch 102/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.0481 - val_loss: -6.0761\n",
      "Epoch 103/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.0559 - val_loss: -6.0794\n",
      "Epoch 104/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.0640 - val_loss: -6.0847\n",
      "Epoch 105/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.0702 - val_loss: -6.0957\n",
      "Epoch 106/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.0768 - val_loss: -6.0882\n",
      "Epoch 107/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.0832 - val_loss: -6.0946\n",
      "Epoch 108/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.0904 - val_loss: -6.0982\n",
      "Epoch 109/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.0964 - val_loss: -6.1009\n",
      "Epoch 110/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.1016 - val_loss: -6.1058\n",
      "Epoch 111/800\n",
      "603/603 [==============================] - 0s 46us/step - loss: -7.1075 - val_loss: -6.1060\n",
      "Epoch 112/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.1143 - val_loss: -6.1008\n",
      "Epoch 113/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.1202 - val_loss: -6.1113\n",
      "Epoch 114/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.1259 - val_loss: -6.1099\n",
      "Epoch 115/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.1323 - val_loss: -6.1152\n",
      "Epoch 116/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.1383 - val_loss: -6.1235\n",
      "Epoch 117/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.1422 - val_loss: -6.1223\n",
      "Epoch 118/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.1484 - val_loss: -6.1263\n",
      "Epoch 119/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.1545 - val_loss: -6.1261\n",
      "Epoch 120/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.1596 - val_loss: -6.1275\n",
      "Epoch 121/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.1646 - val_loss: -6.1280\n",
      "Epoch 122/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.1698 - val_loss: -6.1308\n",
      "Epoch 123/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.1749 - val_loss: -6.1386\n",
      "Epoch 124/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -7.1795 - val_loss: -6.1394\n",
      "Epoch 125/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.1838 - val_loss: -6.1450\n",
      "Epoch 126/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.1890 - val_loss: -6.1474\n",
      "Epoch 127/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.1933 - val_loss: -6.1478\n",
      "Epoch 128/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.1975 - val_loss: -6.1525\n",
      "Epoch 129/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.2020 - val_loss: -6.1557\n",
      "Epoch 130/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.2052 - val_loss: -6.1583\n",
      "Epoch 131/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.2109 - val_loss: -6.1591\n",
      "Epoch 132/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.2144 - val_loss: -6.1664\n",
      "Epoch 133/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.2183 - val_loss: -6.1718\n",
      "Epoch 134/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.2227 - val_loss: -6.1689\n",
      "Epoch 135/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.2262 - val_loss: -6.1753\n",
      "Epoch 136/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.2302 - val_loss: -6.1736\n",
      "Epoch 137/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.2342 - val_loss: -6.1778\n",
      "Epoch 138/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -7.2377 - val_loss: -6.1832\n",
      "Epoch 139/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.2420 - val_loss: -6.1808\n",
      "Epoch 140/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.2454 - val_loss: -6.1831\n",
      "Epoch 141/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.2503 - val_loss: -6.1851\n",
      "Epoch 142/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.2524 - val_loss: -6.1922\n",
      "Epoch 143/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.2576 - val_loss: -6.1891\n",
      "Epoch 144/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.2607 - val_loss: -6.1881\n",
      "Epoch 145/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.2644 - val_loss: -6.1963\n",
      "Epoch 146/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.2686 - val_loss: -6.1941\n",
      "Epoch 147/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.2726 - val_loss: -6.1964\n",
      "Epoch 148/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.2768 - val_loss: -6.1988\n",
      "Epoch 149/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -7.2802 - val_loss: -6.2003\n",
      "Epoch 150/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.2833 - val_loss: -6.2021\n",
      "Epoch 151/800\n",
      "603/603 [==============================] - 0s 51us/step - loss: -7.2878 - val_loss: -6.2033\n",
      "Epoch 152/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.2905 - val_loss: -6.2074\n",
      "Epoch 153/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.2948 - val_loss: -6.2071\n",
      "Epoch 154/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.2983 - val_loss: -6.2110\n",
      "Epoch 155/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 30us/step - loss: -7.3014 - val_loss: -6.2136\n",
      "Epoch 156/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.3054 - val_loss: -6.2113\n",
      "Epoch 157/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.3084 - val_loss: -6.2166\n",
      "Epoch 158/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.3124 - val_loss: -6.2205\n",
      "Epoch 159/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.3161 - val_loss: -6.2194\n",
      "Epoch 160/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.3190 - val_loss: -6.2236\n",
      "Epoch 161/800\n",
      "603/603 [==============================] - 0s 56us/step - loss: -7.3223 - val_loss: -6.2257\n",
      "Epoch 162/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.3262 - val_loss: -6.2262\n",
      "Epoch 163/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.3299 - val_loss: -6.2277\n",
      "Epoch 164/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.3322 - val_loss: -6.2216\n",
      "Epoch 165/800\n",
      "603/603 [==============================] - 0s 48us/step - loss: -7.3364 - val_loss: -6.2289\n",
      "Epoch 166/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.3395 - val_loss: -6.2287\n",
      "Epoch 167/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.3427 - val_loss: -6.2273\n",
      "Epoch 168/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.3452 - val_loss: -6.2356\n",
      "Epoch 169/800\n",
      "603/603 [==============================] - 0s 43us/step - loss: -7.3484 - val_loss: -6.2268\n",
      "Epoch 170/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.3523 - val_loss: -6.2409\n",
      "Epoch 171/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.3545 - val_loss: -6.2342\n",
      "Epoch 172/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.3580 - val_loss: -6.2381\n",
      "Epoch 173/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.3608 - val_loss: -6.2437\n",
      "Epoch 174/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.3632 - val_loss: -6.2437\n",
      "Epoch 175/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.3667 - val_loss: -6.2451\n",
      "Epoch 176/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.3691 - val_loss: -6.2492\n",
      "Epoch 177/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.3710 - val_loss: -6.2545\n",
      "Epoch 178/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.3740 - val_loss: -6.2554\n",
      "Epoch 179/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.3774 - val_loss: -6.2575\n",
      "Epoch 180/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.3801 - val_loss: -6.2566\n",
      "Epoch 181/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.3824 - val_loss: -6.2604\n",
      "Epoch 182/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.3854 - val_loss: -6.2587\n",
      "Epoch 183/800\n",
      "603/603 [==============================] - 0s 47us/step - loss: -7.3882 - val_loss: -6.2617\n",
      "Epoch 184/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.3903 - val_loss: -6.2565\n",
      "Epoch 185/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -7.3931 - val_loss: -6.2614\n",
      "Epoch 186/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.3948 - val_loss: -6.2601\n",
      "Epoch 187/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.3982 - val_loss: -6.2633\n",
      "Epoch 188/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.4010 - val_loss: -6.2625\n",
      "Epoch 189/800\n",
      "603/603 [==============================] - 0s 27us/step - loss: -7.4024 - val_loss: -6.2644\n",
      "Epoch 190/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.4058 - val_loss: -6.2646\n",
      "Epoch 191/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -7.4089 - val_loss: -6.2710\n",
      "Epoch 192/800\n",
      "603/603 [==============================] - 0s 57us/step - loss: -7.4111 - val_loss: -6.2722\n",
      "Epoch 193/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.4138 - val_loss: -6.2710\n",
      "Epoch 194/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.4163 - val_loss: -6.2759\n",
      "Epoch 195/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.4185 - val_loss: -6.2780\n",
      "Epoch 196/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.4202 - val_loss: -6.2744\n",
      "Epoch 197/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.4233 - val_loss: -6.2812\n",
      "Epoch 198/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.4260 - val_loss: -6.2808\n",
      "Epoch 199/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.4285 - val_loss: -6.2842\n",
      "Epoch 200/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.4295 - val_loss: -6.2861\n",
      "Epoch 201/800\n",
      "603/603 [==============================] - 0s 53us/step - loss: -7.4342 - val_loss: -6.2896\n",
      "Epoch 202/800\n",
      "603/603 [==============================] - 0s 48us/step - loss: -7.4361 - val_loss: -6.2890\n",
      "Epoch 203/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.4389 - val_loss: -6.2963\n",
      "Epoch 204/800\n",
      "603/603 [==============================] - 0s 46us/step - loss: -7.4416 - val_loss: -6.2992\n",
      "Epoch 205/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.4439 - val_loss: -6.3038\n",
      "Epoch 206/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.4466 - val_loss: -6.3059\n",
      "Epoch 207/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.4499 - val_loss: -6.3063\n",
      "Epoch 208/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.4525 - val_loss: -6.3105\n",
      "Epoch 209/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.4553 - val_loss: -6.3122\n",
      "Epoch 210/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.4581 - val_loss: -6.3156\n",
      "Epoch 211/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.4614 - val_loss: -6.3224\n",
      "Epoch 212/800\n",
      "603/603 [==============================] - 0s 48us/step - loss: -7.4645 - val_loss: -6.3226\n",
      "Epoch 213/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.4671 - val_loss: -6.3267\n",
      "Epoch 214/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.4702 - val_loss: -6.3340\n",
      "Epoch 215/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.4737 - val_loss: -6.3325\n",
      "Epoch 216/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.4766 - val_loss: -6.3399\n",
      "Epoch 217/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -7.4804 - val_loss: -6.3446\n",
      "Epoch 218/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.4834 - val_loss: -6.3461\n",
      "Epoch 219/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.4867 - val_loss: -6.3505\n",
      "Epoch 220/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.4898 - val_loss: -6.3539\n",
      "Epoch 221/800\n",
      "603/603 [==============================] - 0s 49us/step - loss: -7.4941 - val_loss: -6.3619\n",
      "Epoch 222/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.4973 - val_loss: -6.3630\n",
      "Epoch 223/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.5010 - val_loss: -6.3703\n",
      "Epoch 224/800\n",
      "603/603 [==============================] - 0s 45us/step - loss: -7.5048 - val_loss: -6.3684\n",
      "Epoch 225/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.5080 - val_loss: -6.3756\n",
      "Epoch 226/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.5120 - val_loss: -6.3777\n",
      "Epoch 227/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.5151 - val_loss: -6.3827\n",
      "Epoch 228/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.5187 - val_loss: -6.3868\n",
      "Epoch 229/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.5221 - val_loss: -6.3902\n",
      "Epoch 230/800\n",
      "603/603 [==============================] - 0s 29us/step - loss: -7.5258 - val_loss: -6.3911\n",
      "Epoch 231/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.5280 - val_loss: -6.3929\n",
      "Epoch 232/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 38us/step - loss: -7.5313 - val_loss: -6.3935\n",
      "Epoch 233/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.5345 - val_loss: -6.3996\n",
      "Epoch 234/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.5372 - val_loss: -6.3941\n",
      "Epoch 235/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.5398 - val_loss: -6.3987\n",
      "Epoch 236/800\n",
      "603/603 [==============================] - 0s 29us/step - loss: -7.5428 - val_loss: -6.4012\n",
      "Epoch 237/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.5455 - val_loss: -6.4063\n",
      "Epoch 238/800\n",
      "603/603 [==============================] - 0s 26us/step - loss: -7.5486 - val_loss: -6.4086\n",
      "Epoch 239/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.5510 - val_loss: -6.4083\n",
      "Epoch 240/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.5535 - val_loss: -6.4135\n",
      "Epoch 241/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.5566 - val_loss: -6.4159\n",
      "Epoch 242/800\n",
      "603/603 [==============================] - 0s 50us/step - loss: -7.5583 - val_loss: -6.4194\n",
      "Epoch 243/800\n",
      "603/603 [==============================] - 0s 45us/step - loss: -7.5603 - val_loss: -6.4188\n",
      "Epoch 244/800\n",
      "603/603 [==============================] - 0s 27us/step - loss: -7.5627 - val_loss: -6.4224\n",
      "Epoch 245/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.5650 - val_loss: -6.4256\n",
      "Epoch 246/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.5671 - val_loss: -6.4311\n",
      "Epoch 247/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.5688 - val_loss: -6.4336\n",
      "Epoch 248/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.5707 - val_loss: -6.4333\n",
      "Epoch 249/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.5724 - val_loss: -6.4382\n",
      "Epoch 250/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.5746 - val_loss: -6.4440\n",
      "Epoch 251/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -7.5762 - val_loss: -6.4415\n",
      "Epoch 252/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.5780 - val_loss: -6.4473\n",
      "Epoch 253/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.5792 - val_loss: -6.4487\n",
      "Epoch 254/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.5812 - val_loss: -6.4501\n",
      "Epoch 255/800\n",
      "603/603 [==============================] - 0s 29us/step - loss: -7.5831 - val_loss: -6.4528\n",
      "Epoch 256/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.5845 - val_loss: -6.4558\n",
      "Epoch 257/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.5864 - val_loss: -6.4543\n",
      "Epoch 258/800\n",
      "603/603 [==============================] - 0s 43us/step - loss: -7.5878 - val_loss: -6.4622\n",
      "Epoch 259/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.5898 - val_loss: -6.4640\n",
      "Epoch 260/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -7.5910 - val_loss: -6.4661\n",
      "Epoch 261/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.5917 - val_loss: -6.4675\n",
      "Epoch 262/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.5940 - val_loss: -6.4713\n",
      "Epoch 263/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.5949 - val_loss: -6.4763\n",
      "Epoch 264/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.5964 - val_loss: -6.4768\n",
      "Epoch 265/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.5981 - val_loss: -6.4796\n",
      "Epoch 266/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.5991 - val_loss: -6.4802\n",
      "Epoch 267/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.6016 - val_loss: -6.4834\n",
      "Epoch 268/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.6021 - val_loss: -6.4833\n",
      "Epoch 269/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.6033 - val_loss: -6.4866\n",
      "Epoch 270/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.6053 - val_loss: -6.4882\n",
      "Epoch 271/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.6055 - val_loss: -6.4904\n",
      "Epoch 272/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -7.6076 - val_loss: -6.4927\n",
      "Epoch 273/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.6091 - val_loss: -6.4929\n",
      "Epoch 274/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.6100 - val_loss: -6.4964\n",
      "Epoch 275/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.6119 - val_loss: -6.4962\n",
      "Epoch 276/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.6126 - val_loss: -6.4985\n",
      "Epoch 277/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.6139 - val_loss: -6.4978\n",
      "Epoch 278/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.6147 - val_loss: -6.5024\n",
      "Epoch 279/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -7.6162 - val_loss: -6.5013\n",
      "Epoch 280/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.6174 - val_loss: -6.4987\n",
      "Epoch 281/800\n",
      "603/603 [==============================] - 0s 29us/step - loss: -7.6188 - val_loss: -6.5053\n",
      "Epoch 282/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.6195 - val_loss: -6.5044\n",
      "Epoch 283/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.6211 - val_loss: -6.5071\n",
      "Epoch 284/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.6218 - val_loss: -6.5112\n",
      "Epoch 285/800\n",
      "603/603 [==============================] - 0s 45us/step - loss: -7.6235 - val_loss: -6.5085\n",
      "Epoch 286/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.6246 - val_loss: -6.5075\n",
      "Epoch 287/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.6250 - val_loss: -6.5131\n",
      "Epoch 288/800\n",
      "603/603 [==============================] - 0s 27us/step - loss: -7.6268 - val_loss: -6.5088\n",
      "Epoch 289/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.6275 - val_loss: -6.5133\n",
      "Epoch 290/800\n",
      "603/603 [==============================] - 0s 28us/step - loss: -7.6286 - val_loss: -6.5171\n",
      "Epoch 291/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.6287 - val_loss: -6.5151\n",
      "Epoch 292/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.6317 - val_loss: -6.5140\n",
      "Epoch 293/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.6313 - val_loss: -6.5158\n",
      "Epoch 294/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.6334 - val_loss: -6.5178\n",
      "Epoch 295/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.6343 - val_loss: -6.5184\n",
      "Epoch 296/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.6343 - val_loss: -6.5211\n",
      "Epoch 297/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.6363 - val_loss: -6.5206\n",
      "Epoch 298/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.6366 - val_loss: -6.5251\n",
      "Epoch 299/800\n",
      "603/603 [==============================] - 0s 29us/step - loss: -7.6373 - val_loss: -6.5229\n",
      "Epoch 300/800\n",
      "603/603 [==============================] - 0s 29us/step - loss: -7.6385 - val_loss: -6.5251\n",
      "Epoch 301/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.6388 - val_loss: -6.5281\n",
      "Epoch 302/800\n",
      "603/603 [==============================] - 0s 29us/step - loss: -7.6409 - val_loss: -6.5266\n",
      "Epoch 303/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.6409 - val_loss: -6.5308\n",
      "Epoch 304/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.6421 - val_loss: -6.5287\n",
      "Epoch 305/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.6430 - val_loss: -6.5324\n",
      "Epoch 306/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.6437 - val_loss: -6.5335\n",
      "Epoch 307/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.6446 - val_loss: -6.5323\n",
      "Epoch 308/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.6452 - val_loss: -6.5353\n",
      "Epoch 309/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 37us/step - loss: -7.6460 - val_loss: -6.5318\n",
      "Epoch 310/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.6467 - val_loss: -6.5355\n",
      "Epoch 311/800\n",
      "603/603 [==============================] - 0s 43us/step - loss: -7.6478 - val_loss: -6.5362\n",
      "Epoch 312/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.6479 - val_loss: -6.5379\n",
      "Epoch 313/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.6493 - val_loss: -6.5370\n",
      "Epoch 314/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.6500 - val_loss: -6.5400\n",
      "Epoch 315/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.6507 - val_loss: -6.5384\n",
      "Epoch 316/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.6518 - val_loss: -6.5398\n",
      "Epoch 317/800\n",
      "603/603 [==============================] - 0s 43us/step - loss: -7.6522 - val_loss: -6.5395\n",
      "Epoch 318/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.6537 - val_loss: -6.5421\n",
      "Epoch 319/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.6543 - val_loss: -6.5414\n",
      "Epoch 320/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.6539 - val_loss: -6.5420\n",
      "Epoch 321/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.6553 - val_loss: -6.5425\n",
      "Epoch 322/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.6567 - val_loss: -6.5437\n",
      "Epoch 323/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.6576 - val_loss: -6.5454\n",
      "Epoch 324/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.6579 - val_loss: -6.5441\n",
      "Epoch 325/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.6585 - val_loss: -6.5457\n",
      "Epoch 326/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.6586 - val_loss: -6.5461\n",
      "Epoch 327/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.6600 - val_loss: -6.5491\n",
      "Epoch 328/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.6600 - val_loss: -6.5466\n",
      "Epoch 329/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.6616 - val_loss: -6.5480\n",
      "Epoch 330/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.6611 - val_loss: -6.5492\n",
      "Epoch 331/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.6623 - val_loss: -6.5509\n",
      "Epoch 332/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.6633 - val_loss: -6.5493\n",
      "Epoch 333/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.6628 - val_loss: -6.5520\n",
      "Epoch 334/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.6648 - val_loss: -6.5559\n",
      "Epoch 335/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.6654 - val_loss: -6.5542\n",
      "Epoch 336/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.6657 - val_loss: -6.5541\n",
      "Epoch 337/800\n",
      "603/603 [==============================] - 0s 46us/step - loss: -7.6667 - val_loss: -6.5562\n",
      "Epoch 338/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.6667 - val_loss: -6.5554\n",
      "Epoch 339/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.6678 - val_loss: -6.5552\n",
      "Epoch 340/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.6684 - val_loss: -6.5575\n",
      "Epoch 341/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.6698 - val_loss: -6.5544\n",
      "Epoch 342/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.6691 - val_loss: -6.5599\n",
      "Epoch 343/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.6701 - val_loss: -6.5561\n",
      "Epoch 344/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.6713 - val_loss: -6.5582\n",
      "Epoch 345/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.6720 - val_loss: -6.5605\n",
      "Epoch 346/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.6723 - val_loss: -6.5591\n",
      "Epoch 347/800\n",
      "603/603 [==============================] - 0s 27us/step - loss: -7.6734 - val_loss: -6.5626\n",
      "Epoch 348/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.6737 - val_loss: -6.5639\n",
      "Epoch 349/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.6740 - val_loss: -6.5613\n",
      "Epoch 350/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.6749 - val_loss: -6.5621\n",
      "Epoch 351/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.6758 - val_loss: -6.5648\n",
      "Epoch 352/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.6764 - val_loss: -6.5654\n",
      "Epoch 353/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.6768 - val_loss: -6.5673\n",
      "Epoch 354/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.6775 - val_loss: -6.5671\n",
      "Epoch 355/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.6779 - val_loss: -6.5679\n",
      "Epoch 356/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.6789 - val_loss: -6.5678\n",
      "Epoch 357/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.6793 - val_loss: -6.5685\n",
      "Epoch 358/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.6800 - val_loss: -6.5720\n",
      "Epoch 359/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.6806 - val_loss: -6.5686\n",
      "Epoch 360/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.6818 - val_loss: -6.5705\n",
      "Epoch 361/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.6821 - val_loss: -6.5735\n",
      "Epoch 362/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.6827 - val_loss: -6.5728\n",
      "Epoch 363/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.6822 - val_loss: -6.5764\n",
      "Epoch 364/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.6842 - val_loss: -6.5753\n",
      "Epoch 365/800\n",
      "603/603 [==============================] - 0s 45us/step - loss: -7.6844 - val_loss: -6.5785\n",
      "Epoch 366/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.6848 - val_loss: -6.5762\n",
      "Epoch 367/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.6858 - val_loss: -6.5784\n",
      "Epoch 368/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.6870 - val_loss: -6.5784\n",
      "Epoch 369/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.6872 - val_loss: -6.5807\n",
      "Epoch 370/800\n",
      "603/603 [==============================] - 0s 28us/step - loss: -7.6878 - val_loss: -6.5777\n",
      "Epoch 371/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.6876 - val_loss: -6.5843\n",
      "Epoch 372/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.6893 - val_loss: -6.5835\n",
      "Epoch 373/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.6897 - val_loss: -6.5842\n",
      "Epoch 374/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.6909 - val_loss: -6.5866\n",
      "Epoch 375/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.6917 - val_loss: -6.5864\n",
      "Epoch 376/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.6918 - val_loss: -6.5835\n",
      "Epoch 377/800\n",
      "603/603 [==============================] - 0s 43us/step - loss: -7.6926 - val_loss: -6.5878\n",
      "Epoch 378/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.6932 - val_loss: -6.5879\n",
      "Epoch 379/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.6937 - val_loss: -6.5857\n",
      "Epoch 380/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.6945 - val_loss: -6.5903\n",
      "Epoch 381/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.6950 - val_loss: -6.5868\n",
      "Epoch 382/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.6951 - val_loss: -6.5919\n",
      "Epoch 383/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.6962 - val_loss: -6.5914\n",
      "Epoch 384/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.6972 - val_loss: -6.5923\n",
      "Epoch 385/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.6976 - val_loss: -6.5918\n",
      "Epoch 386/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 38us/step - loss: -7.6989 - val_loss: -6.5963\n",
      "Epoch 387/800\n",
      "603/603 [==============================] - 0s 28us/step - loss: -7.6983 - val_loss: -6.5925\n",
      "Epoch 388/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.6998 - val_loss: -6.5972\n",
      "Epoch 389/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.7005 - val_loss: -6.5977\n",
      "Epoch 390/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7011 - val_loss: -6.5954\n",
      "Epoch 391/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7016 - val_loss: -6.5956\n",
      "Epoch 392/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.7018 - val_loss: -6.5972\n",
      "Epoch 393/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7030 - val_loss: -6.5998\n",
      "Epoch 394/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.7035 - val_loss: -6.5970\n",
      "Epoch 395/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.7040 - val_loss: -6.5997\n",
      "Epoch 396/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -7.7044 - val_loss: -6.5979\n",
      "Epoch 397/800\n",
      "603/603 [==============================] - 0s 27us/step - loss: -7.7051 - val_loss: -6.6009\n",
      "Epoch 398/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.7060 - val_loss: -6.6028\n",
      "Epoch 399/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.7069 - val_loss: -6.6014\n",
      "Epoch 400/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7071 - val_loss: -6.6019\n",
      "Epoch 401/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.7077 - val_loss: -6.6040\n",
      "Epoch 402/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.7087 - val_loss: -6.6040\n",
      "Epoch 403/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.7098 - val_loss: -6.6070\n",
      "Epoch 404/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.7106 - val_loss: -6.6061\n",
      "Epoch 405/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.7099 - val_loss: -6.6097\n",
      "Epoch 406/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.7116 - val_loss: -6.6072\n",
      "Epoch 407/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.7118 - val_loss: -6.6103\n",
      "Epoch 408/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.7126 - val_loss: -6.6100\n",
      "Epoch 409/800\n",
      "603/603 [==============================] - 0s 28us/step - loss: -7.7131 - val_loss: -6.6130\n",
      "Epoch 410/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7137 - val_loss: -6.6107\n",
      "Epoch 411/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.7145 - val_loss: -6.6128\n",
      "Epoch 412/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7152 - val_loss: -6.6123\n",
      "Epoch 413/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7161 - val_loss: -6.6143\n",
      "Epoch 414/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7166 - val_loss: -6.6133\n",
      "Epoch 415/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.7170 - val_loss: -6.6190\n",
      "Epoch 416/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.7178 - val_loss: -6.6180\n",
      "Epoch 417/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7185 - val_loss: -6.6202\n",
      "Epoch 418/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7197 - val_loss: -6.6184\n",
      "Epoch 419/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.7187 - val_loss: -6.6179\n",
      "Epoch 420/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.7207 - val_loss: -6.6195\n",
      "Epoch 421/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7214 - val_loss: -6.6208\n",
      "Epoch 422/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.7221 - val_loss: -6.6228\n",
      "Epoch 423/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.7226 - val_loss: -6.6248\n",
      "Epoch 424/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.7232 - val_loss: -6.6252\n",
      "Epoch 425/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.7242 - val_loss: -6.6248\n",
      "Epoch 426/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.7248 - val_loss: -6.6265\n",
      "Epoch 427/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.7254 - val_loss: -6.6257\n",
      "Epoch 428/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.7261 - val_loss: -6.6281\n",
      "Epoch 429/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.7269 - val_loss: -6.6279\n",
      "Epoch 430/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.7277 - val_loss: -6.6317\n",
      "Epoch 431/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7280 - val_loss: -6.6316\n",
      "Epoch 432/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.7289 - val_loss: -6.6326\n",
      "Epoch 433/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7298 - val_loss: -6.6323\n",
      "Epoch 434/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.7300 - val_loss: -6.6362\n",
      "Epoch 435/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.7309 - val_loss: -6.6372\n",
      "Epoch 436/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.7320 - val_loss: -6.6376\n",
      "Epoch 437/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.7323 - val_loss: -6.6369\n",
      "Epoch 438/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7330 - val_loss: -6.6389\n",
      "Epoch 439/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.7343 - val_loss: -6.6425\n",
      "Epoch 440/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.7349 - val_loss: -6.6422\n",
      "Epoch 441/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.7356 - val_loss: -6.6437\n",
      "Epoch 442/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.7361 - val_loss: -6.6419\n",
      "Epoch 443/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.7369 - val_loss: -6.6451\n",
      "Epoch 444/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7374 - val_loss: -6.6469\n",
      "Epoch 445/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.7388 - val_loss: -6.6454\n",
      "Epoch 446/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.7391 - val_loss: -6.6483\n",
      "Epoch 447/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.7401 - val_loss: -6.6490\n",
      "Epoch 448/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.7407 - val_loss: -6.6490\n",
      "Epoch 449/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7417 - val_loss: -6.6528\n",
      "Epoch 450/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.7427 - val_loss: -6.6527\n",
      "Epoch 451/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.7430 - val_loss: -6.6541\n",
      "Epoch 452/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.7442 - val_loss: -6.6569\n",
      "Epoch 453/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.7451 - val_loss: -6.6574\n",
      "Epoch 454/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.7456 - val_loss: -6.6585\n",
      "Epoch 455/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.7459 - val_loss: -6.6553\n",
      "Epoch 456/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.7472 - val_loss: -6.6586\n",
      "Epoch 457/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7477 - val_loss: -6.6621\n",
      "Epoch 458/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7481 - val_loss: -6.6636\n",
      "Epoch 459/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7496 - val_loss: -6.6609\n",
      "Epoch 460/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.7500 - val_loss: -6.6612\n",
      "Epoch 461/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7510 - val_loss: -6.6648\n",
      "Epoch 462/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.7520 - val_loss: -6.6665\n",
      "Epoch 463/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 35us/step - loss: -7.7529 - val_loss: -6.6673\n",
      "Epoch 464/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.7530 - val_loss: -6.6676\n",
      "Epoch 465/800\n",
      "603/603 [==============================] - 0s 43us/step - loss: -7.7542 - val_loss: -6.6705\n",
      "Epoch 466/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.7544 - val_loss: -6.6712\n",
      "Epoch 467/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.7558 - val_loss: -6.6672\n",
      "Epoch 468/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.7560 - val_loss: -6.6705\n",
      "Epoch 469/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.7579 - val_loss: -6.6721\n",
      "Epoch 470/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.7584 - val_loss: -6.6764\n",
      "Epoch 471/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.7589 - val_loss: -6.6753\n",
      "Epoch 472/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7599 - val_loss: -6.6795\n",
      "Epoch 473/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.7609 - val_loss: -6.6753\n",
      "Epoch 474/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7615 - val_loss: -6.6763\n",
      "Epoch 475/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.7620 - val_loss: -6.6774\n",
      "Epoch 476/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.7627 - val_loss: -6.6782\n",
      "Epoch 477/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.7636 - val_loss: -6.6771\n",
      "Epoch 478/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.7643 - val_loss: -6.6814\n",
      "Epoch 479/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.7652 - val_loss: -6.6876\n",
      "Epoch 480/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.7660 - val_loss: -6.6889\n",
      "Epoch 481/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.7670 - val_loss: -6.6899\n",
      "Epoch 482/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.7677 - val_loss: -6.6886\n",
      "Epoch 483/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.7682 - val_loss: -6.6872\n",
      "Epoch 484/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.7687 - val_loss: -6.6843\n",
      "Epoch 485/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.7697 - val_loss: -6.6812\n",
      "Epoch 486/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.7696 - val_loss: -6.6887\n",
      "Epoch 487/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.7712 - val_loss: -6.6897\n",
      "Epoch 488/800\n",
      "603/603 [==============================] - 0s 43us/step - loss: -7.7719 - val_loss: -6.6968\n",
      "Epoch 489/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7727 - val_loss: -6.6916\n",
      "Epoch 490/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.7733 - val_loss: -6.6932\n",
      "Epoch 491/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.7741 - val_loss: -6.6907\n",
      "Epoch 492/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7744 - val_loss: -6.6974\n",
      "Epoch 493/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7756 - val_loss: -6.6967\n",
      "Epoch 494/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.7759 - val_loss: -6.6939\n",
      "Epoch 495/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.7766 - val_loss: -6.6984\n",
      "Epoch 496/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.7772 - val_loss: -6.6983\n",
      "Epoch 497/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.7778 - val_loss: -6.6964\n",
      "Epoch 498/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.7784 - val_loss: -6.6996\n",
      "Epoch 499/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.7786 - val_loss: -6.6992\n",
      "Epoch 500/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.7795 - val_loss: -6.7016\n",
      "Epoch 501/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.7802 - val_loss: -6.7027\n",
      "Epoch 502/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -7.7806 - val_loss: -6.6969\n",
      "Epoch 503/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.7815 - val_loss: -6.7016\n",
      "Epoch 504/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.7816 - val_loss: -6.7019\n",
      "Epoch 505/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.7821 - val_loss: -6.7013\n",
      "Epoch 506/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.7824 - val_loss: -6.7037\n",
      "Epoch 507/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.7829 - val_loss: -6.7037\n",
      "Epoch 508/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.7840 - val_loss: -6.7000\n",
      "Epoch 509/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.7837 - val_loss: -6.7022\n",
      "Epoch 510/800\n",
      "603/603 [==============================] - 0s 43us/step - loss: -7.7843 - val_loss: -6.7030\n",
      "Epoch 511/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.7847 - val_loss: -6.7053\n",
      "Epoch 512/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.7853 - val_loss: -6.7035\n",
      "Epoch 513/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.7859 - val_loss: -6.7053\n",
      "Epoch 514/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.7863 - val_loss: -6.7033\n",
      "Epoch 515/800\n",
      "603/603 [==============================] - 0s 29us/step - loss: -7.7868 - val_loss: -6.7054\n",
      "Epoch 516/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -7.7873 - val_loss: -6.7064\n",
      "Epoch 517/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.7877 - val_loss: -6.7071\n",
      "Epoch 518/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.7881 - val_loss: -6.7021\n",
      "Epoch 519/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.7881 - val_loss: -6.7023\n",
      "Epoch 520/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.7886 - val_loss: -6.7068\n",
      "Epoch 521/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.7892 - val_loss: -6.7055\n",
      "Epoch 522/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.7896 - val_loss: -6.7039\n",
      "Epoch 523/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7899 - val_loss: -6.7055\n",
      "Epoch 524/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.7902 - val_loss: -6.7064\n",
      "Epoch 525/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7908 - val_loss: -6.6994\n",
      "Epoch 526/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.7905 - val_loss: -6.7039\n",
      "Epoch 527/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.7915 - val_loss: -6.7065\n",
      "Epoch 528/800\n",
      "603/603 [==============================] - ETA: 0s - loss: -6.96 - 0s 34us/step - loss: -7.7917 - val_loss: -6.7080\n",
      "Epoch 529/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.7925 - val_loss: -6.7039\n",
      "Epoch 530/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.7925 - val_loss: -6.7043\n",
      "Epoch 531/800\n",
      "603/603 [==============================] - 0s 28us/step - loss: -7.7931 - val_loss: -6.7090\n",
      "Epoch 532/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.7930 - val_loss: -6.7096\n",
      "Epoch 533/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.7941 - val_loss: -6.7044\n",
      "Epoch 534/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.7942 - val_loss: -6.7090\n",
      "Epoch 535/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.7949 - val_loss: -6.7049\n",
      "Epoch 536/800\n",
      "603/603 [==============================] - 0s 29us/step - loss: -7.7944 - val_loss: -6.7031\n",
      "Epoch 537/800\n",
      "603/603 [==============================] - 0s 28us/step - loss: -7.7954 - val_loss: -6.7059\n",
      "Epoch 538/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.7958 - val_loss: -6.7085\n",
      "Epoch 539/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7959 - val_loss: -6.7050\n",
      "Epoch 540/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 32us/step - loss: -7.7961 - val_loss: -6.7047\n",
      "Epoch 541/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.7967 - val_loss: -6.7054\n",
      "Epoch 542/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.7969 - val_loss: -6.7034\n",
      "Epoch 543/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7976 - val_loss: -6.7077\n",
      "Epoch 544/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.7979 - val_loss: -6.7086\n",
      "Epoch 545/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.7983 - val_loss: -6.7075\n",
      "Epoch 546/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.7988 - val_loss: -6.7065\n",
      "Epoch 547/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.7992 - val_loss: -6.7078\n",
      "Epoch 548/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.7996 - val_loss: -6.7062\n",
      "Epoch 549/800\n",
      "603/603 [==============================] - 0s 29us/step - loss: -7.7996 - val_loss: -6.7097\n",
      "Epoch 550/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8000 - val_loss: -6.7106\n",
      "Epoch 551/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8002 - val_loss: -6.7037\n",
      "Epoch 552/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8003 - val_loss: -6.7038\n",
      "Epoch 553/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8009 - val_loss: -6.7094\n",
      "Epoch 554/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.8014 - val_loss: -6.7070\n",
      "Epoch 555/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.8015 - val_loss: -6.7070\n",
      "Epoch 556/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.8017 - val_loss: -6.7099\n",
      "Epoch 557/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.8026 - val_loss: -6.7100\n",
      "Epoch 558/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8029 - val_loss: -6.7089\n",
      "Epoch 559/800\n",
      "603/603 [==============================] - 0s 49us/step - loss: -7.8034 - val_loss: -6.7038\n",
      "Epoch 560/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8030 - val_loss: -6.7088\n",
      "Epoch 561/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.8035 - val_loss: -6.7101\n",
      "Epoch 562/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.8042 - val_loss: -6.7088\n",
      "Epoch 563/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.8044 - val_loss: -6.7103\n",
      "Epoch 564/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.8048 - val_loss: -6.7090\n",
      "Epoch 565/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8052 - val_loss: -6.7121\n",
      "Epoch 566/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8054 - val_loss: -6.7117\n",
      "Epoch 567/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8058 - val_loss: -6.7088\n",
      "Epoch 568/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8064 - val_loss: -6.7123\n",
      "Epoch 569/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8056 - val_loss: -6.7142\n",
      "Epoch 570/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8064 - val_loss: -6.7104\n",
      "Epoch 571/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8074 - val_loss: -6.7094\n",
      "Epoch 572/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8074 - val_loss: -6.7108\n",
      "Epoch 573/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8074 - val_loss: -6.7114\n",
      "Epoch 574/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8080 - val_loss: -6.7078\n",
      "Epoch 575/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8080 - val_loss: -6.7075\n",
      "Epoch 576/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8081 - val_loss: -6.7080\n",
      "Epoch 577/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.8087 - val_loss: -6.7100\n",
      "Epoch 578/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8090 - val_loss: -6.7110\n",
      "Epoch 579/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.8094 - val_loss: -6.7119\n",
      "Epoch 580/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8100 - val_loss: -6.7144\n",
      "Epoch 581/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8098 - val_loss: -6.7083\n",
      "Epoch 582/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8098 - val_loss: -6.7128\n",
      "Epoch 583/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.8110 - val_loss: -6.7084\n",
      "Epoch 584/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.8107 - val_loss: -6.7134\n",
      "Epoch 585/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.8113 - val_loss: -6.7128\n",
      "Epoch 586/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8118 - val_loss: -6.7120\n",
      "Epoch 587/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8118 - val_loss: -6.7123\n",
      "Epoch 588/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8124 - val_loss: -6.7106\n",
      "Epoch 589/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8122 - val_loss: -6.7120\n",
      "Epoch 590/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.8127 - val_loss: -6.7173\n",
      "Epoch 591/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.8126 - val_loss: -6.7116\n",
      "Epoch 592/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8129 - val_loss: -6.7077\n",
      "Epoch 593/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8133 - val_loss: -6.7124\n",
      "Epoch 594/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8139 - val_loss: -6.7116\n",
      "Epoch 595/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.8142 - val_loss: -6.7115\n",
      "Epoch 596/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8141 - val_loss: -6.7119\n",
      "Epoch 597/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8142 - val_loss: -6.7156\n",
      "Epoch 598/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8147 - val_loss: -6.7120\n",
      "Epoch 599/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8151 - val_loss: -6.7106\n",
      "Epoch 600/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8152 - val_loss: -6.7068\n",
      "Epoch 601/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.8152 - val_loss: -6.7080\n",
      "Epoch 602/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8152 - val_loss: -6.7140\n",
      "Epoch 603/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8159 - val_loss: -6.7122\n",
      "Epoch 604/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8163 - val_loss: -6.7086\n",
      "Epoch 605/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8166 - val_loss: -6.7082\n",
      "Epoch 606/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8162 - val_loss: -6.7128\n",
      "Epoch 607/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8169 - val_loss: -6.7103\n",
      "Epoch 608/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8172 - val_loss: -6.7109\n",
      "Epoch 609/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.8174 - val_loss: -6.7108\n",
      "Epoch 610/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8176 - val_loss: -6.7134\n",
      "Epoch 611/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8183 - val_loss: -6.7124\n",
      "Epoch 612/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.8179 - val_loss: -6.7108\n",
      "Epoch 613/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.8184 - val_loss: -6.7082\n",
      "Epoch 614/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.8185 - val_loss: -6.7144\n",
      "Epoch 615/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8187 - val_loss: -6.7145\n",
      "Epoch 616/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.8188 - val_loss: -6.7152\n",
      "Epoch 617/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 30us/step - loss: -7.8193 - val_loss: -6.7113\n",
      "Epoch 618/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8193 - val_loss: -6.7112\n",
      "Epoch 619/800\n",
      "603/603 [==============================] - 0s 29us/step - loss: -7.8197 - val_loss: -6.7128\n",
      "Epoch 620/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -7.8200 - val_loss: -6.7166\n",
      "Epoch 621/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8203 - val_loss: -6.7150\n",
      "Epoch 622/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.8206 - val_loss: -6.7105\n",
      "Epoch 623/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.8203 - val_loss: -6.7149\n",
      "Epoch 624/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8208 - val_loss: -6.7129\n",
      "Epoch 625/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8210 - val_loss: -6.7109\n",
      "Epoch 626/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8220 - val_loss: -6.7144\n",
      "Epoch 627/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8217 - val_loss: -6.7161\n",
      "Epoch 628/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8220 - val_loss: -6.7146\n",
      "Epoch 629/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.8223 - val_loss: -6.7118\n",
      "Epoch 630/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.8222 - val_loss: -6.7133\n",
      "Epoch 631/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8226 - val_loss: -6.7136\n",
      "Epoch 632/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8229 - val_loss: -6.7156\n",
      "Epoch 633/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8228 - val_loss: -6.7167\n",
      "Epoch 634/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.8236 - val_loss: -6.7131\n",
      "Epoch 635/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8240 - val_loss: -6.7158\n",
      "Epoch 636/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8238 - val_loss: -6.7159\n",
      "Epoch 637/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8244 - val_loss: -6.7158\n",
      "Epoch 638/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8242 - val_loss: -6.7140\n",
      "Epoch 639/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8244 - val_loss: -6.7186\n",
      "Epoch 640/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8246 - val_loss: -6.7153\n",
      "Epoch 641/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8252 - val_loss: -6.7160\n",
      "Epoch 642/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8251 - val_loss: -6.7139\n",
      "Epoch 643/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8256 - val_loss: -6.7159\n",
      "Epoch 644/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8258 - val_loss: -6.7178\n",
      "Epoch 645/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8260 - val_loss: -6.7136\n",
      "Epoch 646/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8261 - val_loss: -6.7166\n",
      "Epoch 647/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8265 - val_loss: -6.7189\n",
      "Epoch 648/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.8263 - val_loss: -6.7192\n",
      "Epoch 649/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8269 - val_loss: -6.7160\n",
      "Epoch 650/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8271 - val_loss: -6.7164\n",
      "Epoch 651/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.8271 - val_loss: -6.7167\n",
      "Epoch 652/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8273 - val_loss: -6.7140\n",
      "Epoch 653/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8272 - val_loss: -6.7208\n",
      "Epoch 654/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8277 - val_loss: -6.7174\n",
      "Epoch 655/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.8277 - val_loss: -6.7176\n",
      "Epoch 656/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8284 - val_loss: -6.7212\n",
      "Epoch 657/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -7.8287 - val_loss: -6.7200\n",
      "Epoch 658/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8285 - val_loss: -6.7187\n",
      "Epoch 659/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.8285 - val_loss: -6.7163\n",
      "Epoch 660/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8294 - val_loss: -6.7233\n",
      "Epoch 661/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8295 - val_loss: -6.7214\n",
      "Epoch 662/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8297 - val_loss: -6.7245\n",
      "Epoch 663/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8299 - val_loss: -6.7164\n",
      "Epoch 664/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8298 - val_loss: -6.7197\n",
      "Epoch 665/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.8303 - val_loss: -6.7187\n",
      "Epoch 666/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8304 - val_loss: -6.7156\n",
      "Epoch 667/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8304 - val_loss: -6.7172\n",
      "Epoch 668/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8310 - val_loss: -6.7138\n",
      "Epoch 669/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8306 - val_loss: -6.7227\n",
      "Epoch 670/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8316 - val_loss: -6.7225\n",
      "Epoch 671/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8317 - val_loss: -6.7213\n",
      "Epoch 672/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.8320 - val_loss: -6.7173\n",
      "Epoch 673/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.8311 - val_loss: -6.7186\n",
      "Epoch 674/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8322 - val_loss: -6.7269\n",
      "Epoch 675/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8323 - val_loss: -6.7241\n",
      "Epoch 676/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.8323 - val_loss: -6.7231\n",
      "Epoch 677/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8327 - val_loss: -6.7221\n",
      "Epoch 678/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.8332 - val_loss: -6.7158\n",
      "Epoch 679/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8328 - val_loss: -6.7212\n",
      "Epoch 680/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8333 - val_loss: -6.7226\n",
      "Epoch 681/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8338 - val_loss: -6.7232\n",
      "Epoch 682/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.8338 - val_loss: -6.7210\n",
      "Epoch 683/800\n",
      "603/603 [==============================] - 0s 43us/step - loss: -7.8341 - val_loss: -6.7235\n",
      "Epoch 684/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8338 - val_loss: -6.7238\n",
      "Epoch 685/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8339 - val_loss: -6.7245\n",
      "Epoch 686/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8342 - val_loss: -6.7242\n",
      "Epoch 687/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.8349 - val_loss: -6.7232\n",
      "Epoch 688/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8350 - val_loss: -6.7219\n",
      "Epoch 689/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8350 - val_loss: -6.7261\n",
      "Epoch 690/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8355 - val_loss: -6.7195\n",
      "Epoch 691/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.8356 - val_loss: -6.7171\n",
      "Epoch 692/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8353 - val_loss: -6.7178\n",
      "Epoch 693/800\n",
      "603/603 [==============================] - 0s 48us/step - loss: -7.8356 - val_loss: -6.7256\n",
      "Epoch 694/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 35us/step - loss: -7.8360 - val_loss: -6.7217\n",
      "Epoch 695/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.8363 - val_loss: -6.7266\n",
      "Epoch 696/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8365 - val_loss: -6.7191\n",
      "Epoch 697/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8367 - val_loss: -6.7176\n",
      "Epoch 698/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8368 - val_loss: -6.7158\n",
      "Epoch 699/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8367 - val_loss: -6.7230\n",
      "Epoch 700/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8372 - val_loss: -6.7233\n",
      "Epoch 701/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8374 - val_loss: -6.7253\n",
      "Epoch 702/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.8373 - val_loss: -6.7214\n",
      "Epoch 703/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.8373 - val_loss: -6.7217\n",
      "Epoch 704/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8375 - val_loss: -6.7224\n",
      "Epoch 705/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.8382 - val_loss: -6.7251\n",
      "Epoch 706/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8383 - val_loss: -6.7226\n",
      "Epoch 707/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8382 - val_loss: -6.7176\n",
      "Epoch 708/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -7.8385 - val_loss: -6.7251\n",
      "Epoch 709/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.8389 - val_loss: -6.7170\n",
      "Epoch 710/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8389 - val_loss: -6.7248\n",
      "Epoch 711/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8392 - val_loss: -6.7227\n",
      "Epoch 712/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8394 - val_loss: -6.7181\n",
      "Epoch 713/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8397 - val_loss: -6.7172\n",
      "Epoch 714/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8395 - val_loss: -6.7250\n",
      "Epoch 715/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8397 - val_loss: -6.7179\n",
      "Epoch 716/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8401 - val_loss: -6.7222\n",
      "Epoch 717/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8402 - val_loss: -6.7209\n",
      "Epoch 718/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8406 - val_loss: -6.7248\n",
      "Epoch 719/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8406 - val_loss: -6.7188\n",
      "Epoch 720/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.8409 - val_loss: -6.7250\n",
      "Epoch 721/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8411 - val_loss: -6.7254\n",
      "Epoch 722/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8411 - val_loss: -6.7240\n",
      "Epoch 723/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8411 - val_loss: -6.7229\n",
      "Epoch 724/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8415 - val_loss: -6.7246\n",
      "Epoch 725/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8416 - val_loss: -6.7223\n",
      "Epoch 726/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8419 - val_loss: -6.7252\n",
      "Epoch 727/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8420 - val_loss: -6.7224\n",
      "Epoch 728/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.8417 - val_loss: -6.7202\n",
      "Epoch 729/800\n",
      "603/603 [==============================] - 0s 44us/step - loss: -7.8422 - val_loss: -6.7255\n",
      "Epoch 730/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8427 - val_loss: -6.7260\n",
      "Epoch 731/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8425 - val_loss: -6.7217\n",
      "Epoch 732/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.8423 - val_loss: -6.7216\n",
      "Epoch 733/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8429 - val_loss: -6.7195\n",
      "Epoch 734/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8432 - val_loss: -6.7225\n",
      "Epoch 735/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.8431 - val_loss: -6.7201\n",
      "Epoch 736/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8432 - val_loss: -6.7265\n",
      "Epoch 737/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8436 - val_loss: -6.7267\n",
      "Epoch 738/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.8437 - val_loss: -6.7205\n",
      "Epoch 739/800\n",
      "603/603 [==============================] - 0s 43us/step - loss: -7.8440 - val_loss: -6.7198\n",
      "Epoch 740/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8442 - val_loss: -6.7250\n",
      "Epoch 741/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8444 - val_loss: -6.7274\n",
      "Epoch 742/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.8446 - val_loss: -6.7174\n",
      "Epoch 743/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.8441 - val_loss: -6.7242\n",
      "Epoch 744/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.8449 - val_loss: -6.7257\n",
      "Epoch 745/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8450 - val_loss: -6.7248\n",
      "Epoch 746/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.8444 - val_loss: -6.7258\n",
      "Epoch 747/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.8455 - val_loss: -6.7297\n",
      "Epoch 748/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8453 - val_loss: -6.7254\n",
      "Epoch 749/800\n",
      "603/603 [==============================] - 0s 27us/step - loss: -7.8451 - val_loss: -6.7236\n",
      "Epoch 750/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8460 - val_loss: -6.7237\n",
      "Epoch 751/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.8458 - val_loss: -6.7299\n",
      "Epoch 752/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8464 - val_loss: -6.7257\n",
      "Epoch 753/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8464 - val_loss: -6.7268\n",
      "Epoch 754/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8463 - val_loss: -6.7224\n",
      "Epoch 755/800\n",
      "603/603 [==============================] - 0s 31us/step - loss: -7.8468 - val_loss: -6.7239\n",
      "Epoch 756/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.8462 - val_loss: -6.7295\n",
      "Epoch 757/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.8470 - val_loss: -6.7259\n",
      "Epoch 758/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8470 - val_loss: -6.7314\n",
      "Epoch 759/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.8476 - val_loss: -6.7307\n",
      "Epoch 760/800\n",
      "603/603 [==============================] - 0s 42us/step - loss: -7.8476 - val_loss: -6.7288\n",
      "Epoch 761/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8475 - val_loss: -6.7289\n",
      "Epoch 762/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8481 - val_loss: -6.7245\n",
      "Epoch 763/800\n",
      "603/603 [==============================] - 0s 41us/step - loss: -7.8480 - val_loss: -6.7298\n",
      "Epoch 764/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8483 - val_loss: -6.7295\n",
      "Epoch 765/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8486 - val_loss: -6.7294\n",
      "Epoch 766/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.8484 - val_loss: -6.7259\n",
      "Epoch 767/800\n",
      "603/603 [==============================] - 0s 30us/step - loss: -7.8483 - val_loss: -6.7285\n",
      "Epoch 768/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.8484 - val_loss: -6.7288\n",
      "Epoch 769/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8485 - val_loss: -6.7330\n",
      "Epoch 770/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8490 - val_loss: -6.7333\n",
      "Epoch 771/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 29us/step - loss: -7.8493 - val_loss: -6.7286\n",
      "Epoch 772/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8490 - val_loss: -6.7254\n",
      "Epoch 773/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.8491 - val_loss: -6.7296\n",
      "Epoch 774/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8494 - val_loss: -6.7290\n",
      "Epoch 775/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8496 - val_loss: -6.7313\n",
      "Epoch 776/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8497 - val_loss: -6.7299\n",
      "Epoch 777/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8501 - val_loss: -6.7306\n",
      "Epoch 778/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8502 - val_loss: -6.7292\n",
      "Epoch 779/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8499 - val_loss: -6.7279\n",
      "Epoch 780/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8503 - val_loss: -6.7263\n",
      "Epoch 781/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8505 - val_loss: -6.7352\n",
      "Epoch 782/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8507 - val_loss: -6.7325\n",
      "Epoch 783/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8507 - val_loss: -6.7389\n",
      "Epoch 784/800\n",
      "603/603 [==============================] - 0s 38us/step - loss: -7.8511 - val_loss: -6.7311\n",
      "Epoch 785/800\n",
      "603/603 [==============================] - 0s 47us/step - loss: -7.8514 - val_loss: -6.7314\n",
      "Epoch 786/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8511 - val_loss: -6.7351\n",
      "Epoch 787/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.8517 - val_loss: -6.7326\n",
      "Epoch 788/800\n",
      "603/603 [==============================] - 0s 34us/step - loss: -7.8515 - val_loss: -6.7326\n",
      "Epoch 789/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8517 - val_loss: -6.7336\n",
      "Epoch 790/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8523 - val_loss: -6.7311\n",
      "Epoch 791/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8519 - val_loss: -6.7352\n",
      "Epoch 792/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8517 - val_loss: -6.7309\n",
      "Epoch 793/800\n",
      "603/603 [==============================] - 0s 32us/step - loss: -7.8523 - val_loss: -6.7280\n",
      "Epoch 794/800\n",
      "603/603 [==============================] - 0s 33us/step - loss: -7.8523 - val_loss: -6.7300\n",
      "Epoch 795/800\n",
      "603/603 [==============================] - 0s 39us/step - loss: -7.8528 - val_loss: -6.7310\n",
      "Epoch 796/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8530 - val_loss: -6.7309\n",
      "Epoch 797/800\n",
      "603/603 [==============================] - 0s 40us/step - loss: -7.8529 - val_loss: -6.7323\n",
      "Epoch 798/800\n",
      "603/603 [==============================] - 0s 37us/step - loss: -7.8531 - val_loss: -6.7374\n",
      "Epoch 799/800\n",
      "603/603 [==============================] - 0s 36us/step - loss: -7.8532 - val_loss: -6.7329\n",
      "Epoch 800/800\n",
      "603/603 [==============================] - 0s 35us/step - loss: -7.8536 - val_loss: -6.7321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maher\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "sa = SparseAutoencoder(xtr, 10, 'adamax', 14, 'binary_crossentropy', 800, 32, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.534 0.528\n"
     ]
    }
   ],
   "source": [
    "r_xtr = sa.reconstruct_input(xtr)\n",
    "r_xte = sa.reconstruct_input(xte)\n",
    "\n",
    "c_xtr = sa.extract_compressed_features(xtr)\n",
    "c_xte = sa.extract_compressed_features(xte)\n",
    "error1 = sa.measure_error(xtr,r_xtr)\n",
    "error2 = sa.measure_error(xte,r_xte)\n",
    "print(np.round(error1, 3), np.round(error2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARGF\n",
      "AUC =  0.968\n",
      "AUC =  0.73\n"
     ]
    }
   ],
   "source": [
    "rgf1 = RGF(xtr, xte, ytr, yte, 0.01)\n",
    "rgf2 = RGF(c_xtr, xte, ytr, yte, 0.01)\n",
    "print('ARGF')\n",
    "auc3 = rgf2.measure_accuracy(c_xtr, ytr)\n",
    "auc4 = rgf2.measure_accuracy(c_xte, yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maher\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\maher\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\maher\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\maher\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\maher\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\maher\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGF\n",
      "AUC =  0.963\n",
      "AUC =  0.895\n",
      "ARGF\n",
      "AUC =  0.972\n",
      "AUC =  0.765\n",
      "DT\n",
      "AUC =  1.0\n",
      "AUC =  0.83\n",
      "AUC =  1.0\n",
      "AUC =  0.735\n",
      "RF\n",
      "AUC =  0.994\n",
      "AUC =  0.844\n",
      "AUC =  0.976\n",
      "AUC =  0.724\n",
      "ET\n",
      "AUC =  1.0\n",
      "AUC =  0.792\n",
      "AUC =  1.0\n",
      "AUC =  0.752\n"
     ]
    }
   ],
   "source": [
    "rgf1 = RGF(xtr, xte, ytr, yte, 0.01)\n",
    "rgf2 = RGF(c_xtr, xte, ytr, yte, 0.01)\n",
    "\n",
    "dt1 = TreeModels(xtr, xte, ytr, yte, 'dt')\n",
    "dt2 = TreeModels(c_xtr, xte, ytr, yte, 'dt')\n",
    "\n",
    "rf1 = TreeModels(xtr, xte, ytr, yte, 'rf')\n",
    "rf2 = TreeModels(c_xtr, xte, ytr, yte, 'rf')\n",
    "\n",
    "et1 = TreeModels(xtr, xte, ytr, yte, 'et')\n",
    "et2 = TreeModels(c_xtr, xte, ytr, yte, 'et')\n",
    "\n",
    "print('RGF')\n",
    "auc1 = rgf1.measure_accuracy(xtr, ytr)\n",
    "auc2 = rgf1.measure_accuracy(xte, yte)\n",
    "\n",
    "print('ARGF')\n",
    "auc3 = rgf2.measure_accuracy(c_xtr, ytr)\n",
    "auc4 = rgf2.measure_accuracy(c_xte, yte)\n",
    "\n",
    "print('DT')\n",
    "auc5 = dt1.measure_accuracy(xtr, ytr)\n",
    "auc6 = dt1.measure_accuracy(xte, yte)\n",
    "auc7 = dt2.measure_accuracy(c_xtr, ytr)\n",
    "auc8 = dt2.measure_accuracy(c_xte, yte)\n",
    "\n",
    "print('RF')\n",
    "auc9 = rf1.measure_accuracy(xtr, ytr)\n",
    "auc10 = rf1.measure_accuracy(xte, yte)\n",
    "auc11 = rf2.measure_accuracy(c_xtr, ytr)\n",
    "auc12 = rf2.measure_accuracy(c_xte, yte)\n",
    "\n",
    "print('ET')\n",
    "auc13 = et1.measure_accuracy(xtr, ytr)\n",
    "auc14 = et1.measure_accuracy(xte, yte)\n",
    "auc15 = et2.measure_accuracy(c_xtr, ytr)\n",
    "auc16 = et2.measure_accuracy(c_xte, yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgf.rank_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6076470092509515"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_whole = sa.reconstruct_input(X_whole)\n",
    "c_whole = sa.extract_compressed_features(X_whole)\n",
    "error1 = sa.measure_error(X_whole,r_whole)\n",
    "error1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgfx = rgf1.predict_proba(X_whole)\n",
    "argfx = rgf2.predict_proba(c_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtx = dt2.predict_proba(c_whole)\n",
    "rfx = rf2.predict_proba(c_whole)\n",
    "etx = et2.predict_proba(c_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.vstack((objectid, rgfx[:,0]))\n",
    "np.savetxt(r\"C:\\Users\\maher\\Desktop\\Data_Bhutan\\rgf.csv\", d.T, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = np.vstack((objectid, argfx[:,0]))\n",
    "np.savetxt(r\"C:\\Users\\maher\\Desktop\\Data_Bhutan\\rgf2.csv\", d2.T, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3 = np.vstack((objectid, dtx[:,0]))\n",
    "np.savetxt(r\"C:\\Users\\maher\\Desktop\\Data_Bhutan\\dt.csv\", d3.T, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "d4 = np.vstack((objectid, rfx[:,0]))\n",
    "np.savetxt(r\"C:\\Users\\maher\\Desktop\\Data_Bhutan\\rf.csv\", d4.T, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d5 = np.vstack((objectid, etx[:,0]))\n",
    "np.savetxt(r\"C:\\Users\\maher\\Desktop\\Data_Bhutan\\et.csv\", d5.T, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
